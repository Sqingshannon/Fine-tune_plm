{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ae55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccca6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39.3\n",
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import transformers\n",
    "import peft\n",
    "# print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(peft.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a5d23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab00834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, get_peft_model\n",
    "from peft.utils.other import fsdp_auto_wrap_policy\n",
    "from transformers import EsmForMaskedLM, EsmTokenizer, EsmConfig\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from confit.data_utils import Mutation_Set, split_train, sample_data\n",
    "from confit.stat_utils import spearman, compute_score, BT_loss, KLloss\n",
    "\n",
    "from Bio import SeqIO\n",
    "from transformers import EsmTokenizer\n",
    "\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47024c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/IF1_ECOLI_Kelsic_2016/data.csv')\n",
    "df2 = pd.read_csv('./data/IF1_ECOLI_Kelsic2016_fitness_rich/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b619f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutant</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>MTKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.010750</td>\n",
       "      <td>1</td>\n",
       "      <td>A2T</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>MRKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.981167</td>\n",
       "      <td>1</td>\n",
       "      <td>A2R</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>MSKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.009167</td>\n",
       "      <td>1</td>\n",
       "      <td>A2S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>MIKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.057333</td>\n",
       "      <td>1</td>\n",
       "      <td>A2I</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>MMKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>1</td>\n",
       "      <td>A2M</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                seq  log_fitness  \\\n",
       "0           2  MTKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.010750   \n",
       "1           3  MRKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.981167   \n",
       "2           4  MSKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.009167   \n",
       "3           5  MIKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.057333   \n",
       "4           6  MMKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.035000   \n",
       "\n",
       "   n_mut mutant  PID  mutated_position  \n",
       "0      1    A2T    2                 1  \n",
       "1      1    A2R    3                 1  \n",
       "2      1    A2S    4                 1  \n",
       "3      1    A2I    5                 1  \n",
       "4      1    A2M    6                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69bb06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutant</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>1</td>\n",
       "      <td>M1H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>1</td>\n",
       "      <td>M1G</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>1</td>\n",
       "      <td>M1I</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.080333</td>\n",
       "      <td>1</td>\n",
       "      <td>M1L</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>1</td>\n",
       "      <td>M1N</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                seq  log_fitness  \\\n",
       "0           0  HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.147500   \n",
       "1           1  GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...    -0.001750   \n",
       "2           2  IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.118000   \n",
       "3           3  LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.080333   \n",
       "4           4  NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.407500   \n",
       "\n",
       "   n_mut mutant  PID  mutated_position  \n",
       "0      1    M1H    0                 0  \n",
       "1      1    M1G    1                 0  \n",
       "2      1    M1I    2                 0  \n",
       "3      1    M1L    3                 0  \n",
       "4      1    M1N    4                 0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutant</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, seq, log_fitness, n_mut, mutant, PID, mutated_position]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"n_mut\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419298d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutant</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, seq, log_fitness, n_mut, mutant, PID, mutated_position]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1[\"n_mut\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5658ed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are different.\n"
     ]
    }
   ],
   "source": [
    "if df1.equals(df2):\n",
    "    print(\"The files are the same.\")\n",
    "else:\n",
    "    print(\"The files are different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2e19df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape != df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9308e476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367, 1206)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1),  len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8b128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(1367), np.int64(1206))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df1[\"n_mut\"]), np.sum(df2[\"n_mut\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab33a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df1, df2, on='seq', how='inner', indicator=True, suffixes=('_df1', '_df2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110fd1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_df1</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness_df1</th>\n",
       "      <th>n_mut_df1</th>\n",
       "      <th>mutant_df1</th>\n",
       "      <th>PID_df1</th>\n",
       "      <th>mutated_position_df1</th>\n",
       "      <th>Unnamed: 0_df2</th>\n",
       "      <th>log_fitness_df2</th>\n",
       "      <th>n_mut_df2</th>\n",
       "      <th>mutant_df2</th>\n",
       "      <th>PID_df2</th>\n",
       "      <th>mutated_position_df2</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>MCKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>1</td>\n",
       "      <td>A2C</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>1</td>\n",
       "      <td>A2C</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>MWKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>1</td>\n",
       "      <td>A2W</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>1</td>\n",
       "      <td>A2W</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>MDKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.0375</td>\n",
       "      <td>1</td>\n",
       "      <td>A2D</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0375</td>\n",
       "      <td>1</td>\n",
       "      <td>A2D</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>MEKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.0130</td>\n",
       "      <td>1</td>\n",
       "      <td>A2E</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0130</td>\n",
       "      <td>1</td>\n",
       "      <td>A2E</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>MFKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.0605</td>\n",
       "      <td>1</td>\n",
       "      <td>A2F</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0605</td>\n",
       "      <td>1</td>\n",
       "      <td>A2F</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_df1                                                seq  \\\n",
       "0              18  MCKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "1              19  MWKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "2              20  MDKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "3              21  MEKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "4              22  MFKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "\n",
       "   log_fitness_df1  n_mut_df1 mutant_df1  PID_df1  mutated_position_df1  \\\n",
       "0           0.8935          1        A2C       18                     1   \n",
       "1           0.8330          1        A2W       19                     1   \n",
       "2           1.0375          1        A2D       20                     1   \n",
       "3           1.0130          1        A2E       21                     1   \n",
       "4           1.0605          1        A2F       22                     1   \n",
       "\n",
       "   Unnamed: 0_df2  log_fitness_df2  n_mut_df2 mutant_df2  PID_df2  \\\n",
       "0              16           0.8935          1        A2C       16   \n",
       "1              17           0.8330          1        A2W       17   \n",
       "2              12           1.0375          1        A2D       12   \n",
       "3              11           1.0130          1        A2E       11   \n",
       "4              18           1.0605          1        A2F       18   \n",
       "\n",
       "   mutated_position_df2 _merge  \n",
       "0                     1   both  \n",
       "1                     1   both  \n",
       "2                     1   both  \n",
       "3                     1   both  \n",
       "4                     1   both  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6deab233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1007)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(merged_df[\"log_fitness_df1\"] == merged_df[\"log_fitness_df2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760cebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6458a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers==4.39.3 peft==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d6c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7713972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"data/IF1_ECOLI_Kelsic_2016/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc972125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1367.000000</td>\n",
       "      <td>1367.00000</td>\n",
       "      <td>1367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.792525</td>\n",
       "      <td>683.00000</td>\n",
       "      <td>36.525969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.285799</td>\n",
       "      <td>394.76322</td>\n",
       "      <td>20.775606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.243500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.752125</td>\n",
       "      <td>341.50000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.916750</td>\n",
       "      <td>683.00000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.975125</td>\n",
       "      <td>1024.50000</td>\n",
       "      <td>54.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.120000</td>\n",
       "      <td>1366.00000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_fitness         PID  mutated_position\n",
       "count  1367.000000  1367.00000       1367.000000\n",
       "mean      0.792525   683.00000         36.525969\n",
       "std       0.285799   394.76322         20.775606\n",
       "min      -0.243500     0.00000          1.000000\n",
       "25%       0.752125   341.50000         19.000000\n",
       "50%       0.916750   683.00000         37.000000\n",
       "75%       0.975125  1024.50000         54.500000\n",
       "max       1.120000  1366.00000         72.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3e5fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "      <th>mutant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M1H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M1G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>M1I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.080333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>M1N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  log_fitness  PID  \\\n",
       "0  HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.147500    0   \n",
       "1  GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...    -0.001750    1   \n",
       "2  IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.118000    2   \n",
       "3  LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.080333    3   \n",
       "4  NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.407500    4   \n",
       "\n",
       "   mutated_position mutant  \n",
       "0                 1    M1H  \n",
       "1                 1    M1G  \n",
       "2                 1    M1I  \n",
       "3                 1    M1L  \n",
       "4                 1    M1N  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12177dab",
   "metadata": {},
   "source": [
    "### Debug evaluate part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'IF1_ECOLI_Kelsic2016_fitness_rich'  \n",
    "model_seed = 1 \n",
    "config = {'model': 'ESM-1v'}  \n",
    "save_path = Path(os.path.join('checkpoint', dataset, f'seed{model_seed}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375be73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fa7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c0fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070578f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d827b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9f6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb905065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2463f4",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "915b9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"IF1_ECOLI_Kelsic_2016\"\n",
    "# dataset_name = \"BRCA1_HUMAN_Fields2015-e3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1827e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f'data/{dataset_name}'\n",
    "data = pd.read_csv(f\"{data_dir}/data.csv\")\n",
    "\n",
    "\n",
    "data = data.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0390d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wild type\n",
    "wt_path = f\"{data_dir}/wt.fasta\"\n",
    "wt_seq = str(next(SeqIO.parse(wt_path, \"fasta\")).seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f11514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild-type sequence length: 72\n"
     ]
    }
   ],
   "source": [
    "print(f'Wild-type sequence length: {len(wt_seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b4b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTG\n"
     ]
    }
   ],
   "source": [
    "print(wt_seq[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15946bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VAE\n",
    "# vae_elbo = pd.read_csv(f\"{data_dir}/vae_elbo.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e295be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_elbo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e685408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./confit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46538765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import Mutation_Set, split_train, sample_data\n",
    "from stat_utils import spearman, compute_score, BT_loss, KLloss\n",
    "from train import train, evaluate, main\n",
    "\n",
    "# import os\n",
    "# os.chdir(\"./confit\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01ab8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/shannon/fine-tune_plm'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aaa667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='ConFit train, set hyperparameters')\n",
    "parser.add_argument('--config', type=str, default='48shot_config.yaml', help='the config file name')\n",
    "parser.add_argument('--dataset', type=str, help='the dataset name')\n",
    "parser.add_argument('--sample_seed', type=int, default=0, help='the sample seed for dataset')\n",
    "parser.add_argument('--model_seed', type=int, default=1, help='the random seed for the pretrained model initiate')\n",
    "\n",
    "# Define args manually (replace values as needed)\n",
    "args = parser.parse_args([\n",
    "    '--config', 'config/training_config.yaml',\n",
    "    '--dataset', 'IF1_ECOLI_Kelsic2016_fitness_rich',\n",
    "    '--sample_seed', '0',\n",
    "    '--model_seed', '1'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f958be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.sample_seed)\n",
    "random.seed(args.sample_seed)\n",
    "torch.manual_seed(args.model_seed)\n",
    "torch.cuda.manual_seed_all(args.model_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb20d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d3d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !accelerate launch --config_file config/parallel_config.yaml confit/train.py \\\n",
    "#     --config config/training_config.yaml \\\n",
    "#     --dataset IF1_ECOLI_Kelsic2016_fitness_rich \\\n",
    "#     --sample_seed 0 \\\n",
    "#     --model_seed 1\n",
    "\n",
    "\n",
    "# FAILED REASON:\n",
    "# the error is due to a version mismatch \n",
    "# between accelerate and peft libraries. \n",
    "# accelerate updated and moved get_module_class_from_name \n",
    "# out of FullyShardedDataParallelPlugin, \n",
    "# but peft still expects it there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f11827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================dataset:IF1_ECOLI_Kelsic2016_fitness_rich, preparing data=============\n",
      "==============data preparing done!================\n",
      "========epoch0; training loss :195.61032557487488=================\n",
      "========epoch0; val spearman correlation :0.625563909774436=================\n",
      "========epoch1; training loss :124.10531663894653=================\n",
      "========epoch1; val spearman correlation :0.6992481203007518=================\n",
      "========epoch2; training loss :104.5744423866272=================\n",
      "========epoch2; val spearman correlation :0.7172932330827068=================\n",
      "========epoch3; training loss :81.0411605834961=================\n",
      "========epoch3; val spearman correlation :0.7473684210526315=================\n",
      "========epoch4; training loss :91.0230360031128=================\n",
      "========epoch4; val spearman correlation :0.7593984962406014=================\n",
      "========epoch5; training loss :79.42871284484863=================\n",
      "========epoch5; val spearman correlation :0.7563909774436091=================\n",
      "========epoch6; training loss :74.02298665046692=================\n",
      "========epoch6; val spearman correlation :0.7669172932330827=================\n",
      "========epoch7; training loss :74.78324365615845=================\n",
      "========epoch7; val spearman correlation :0.7293233082706766=================\n",
      "========epoch8; training loss :81.44850540161133=================\n",
      "========epoch8; val spearman correlation :0.7714285714285714=================\n",
      "========epoch9; training loss :73.4760856628418=================\n",
      "========epoch9; val spearman correlation :0.7954887218045112=================\n",
      "========epoch10; training loss :72.50920128822327=================\n",
      "========epoch10; val spearman correlation :0.7999999999999999=================\n",
      "========epoch11; training loss :74.63996481895447=================\n",
      "========epoch11; val spearman correlation :0.7924812030075187=================\n",
      "========epoch12; training loss :73.83155393600464=================\n",
      "========epoch12; val spearman correlation :0.7834586466165413=================\n",
      "========epoch13; training loss :70.04380798339844=================\n",
      "========epoch13; val spearman correlation :0.793984962406015=================\n",
      "========epoch14; training loss :67.2320306301117=================\n",
      "========epoch14; val spearman correlation :0.78796992481203=================\n",
      "========epoch15; training loss :71.39739727973938=================\n",
      "========epoch15; val spearman correlation :0.7999999999999999=================\n",
      "========epoch16; training loss :68.79246234893799=================\n",
      "========epoch16; val spearman correlation :0.8075187969924811=================\n",
      "========epoch17; training loss :75.99795651435852=================\n",
      "========epoch17; val spearman correlation :0.7744360902255639=================\n",
      "========epoch18; training loss :65.23566579818726=================\n",
      "========epoch18; val spearman correlation :0.78796992481203=================\n",
      "========epoch19; training loss :75.89194416999817=================\n",
      "========epoch19; val spearman correlation :0.78796992481203=================\n",
      "=======training done!, test the performance!========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============the test spearman correlation for early stop: 0.6363356177973376==================\n"
     ]
    }
   ],
   "source": [
    "# sys.argv = [\n",
    "#     \"train.py\",\n",
    "#     \"--config\", \"config/training_config.yaml\",  # or 48shot_config.yaml\n",
    "#     \"--config_file\", \"config/parallel_config.yaml\",\n",
    "#     \"--dataset\", \"IF1_ECOLI_Kelsic2016_fitness_rich\",\n",
    "#     \"--sample_seed\", \"0\",\n",
    "#     \"--model_seed\", \"1\",\n",
    "# ]\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cbe503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================dataset:IF1_ECOLI_Kelsic2016_fitness_rich, preparing data=============\n",
      "==============data preparing done!================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "========epoch0; training loss :32.417314887046814=================\n",
      "========epoch0; val spearman correlation :0.6=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "========epoch1; training loss :31.68228793144226=================\n",
      "========epoch1; val spearman correlation :0.6=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "========epoch2; training loss :31.6742285490036=================\n",
      "========epoch2; val spearman correlation :0.6=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "========epoch3; training loss :31.67060273885727=================\n",
      "========epoch3; val spearman correlation :0.6606060606060605=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "========epoch4; training loss :31.66806012392044=================\n",
      "========epoch4; val spearman correlation :0.6363636363636362=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "========epoch5; training loss :31.666012346744537=================\n",
      "========epoch5; val spearman correlation :0.6363636363636362=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "========epoch6; training loss :31.664776980876923=================\n",
      "========epoch6; val spearman correlation :0.6606060606060605=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "========epoch7; training loss :31.664149403572083=================\n",
      "========epoch7; val spearman correlation :0.6969696969696969=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([17], device='cuda:0')] tensor([0.6030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9790], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9110], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([20], device='cuda:0')] tensor([0.9930], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([5], device='cuda:0')] tensor([0.9800], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([50], device='cuda:0')] tensor([0.4260], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.6695], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.2985], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([35], device='cuda:0')] tensor([0.5330], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9915], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([43], device='cuda:0')] tensor([1.1200], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.9085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9630], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9255], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8205], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([27], device='cuda:0')] tensor([0.8490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([19], device='cuda:0')] tensor([0.9643], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([53], device='cuda:0')] tensor([0.9640], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([2], device='cuda:0')] tensor([0.9853], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0085], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([16], device='cuda:0')] tensor([0.9735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.6880], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([30], device='cuda:0')] tensor([1.0070], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([24], device='cuda:0')] tensor([0.9867], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.9170], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9230], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([67], device='cuda:0')] tensor([0.9562], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9377], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([3], device='cuda:0')] tensor([0.9940], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([41], device='cuda:0')] tensor([0.8430], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([25], device='cuda:0')] tensor([0.6500], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([36], device='cuda:0')] tensor([0.9795], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([33], device='cuda:0')] tensor([0.2960], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([48], device='cuda:0')] tensor([0.9520], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([63], device='cuda:0')] tensor([0.7075], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([38], device='cuda:0')] tensor([0.7943], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([15], device='cuda:0')] tensor([0.9683], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([56], device='cuda:0')] tensor([0.9383], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([52], device='cuda:0')] tensor([0.9490], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([57], device='cuda:0')] tensor([0.7580], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([45], device='cuda:0')] tensor([0.6530], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([22], device='cuda:0')] tensor([0.9030], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.3735], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([69], device='cuda:0')] tensor([0.7550], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.5910], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([42], device='cuda:0')] tensor([0.6437], device='cuda:0')\n",
      "========epoch8; training loss :31.66377764940262=================\n",
      "========epoch8; val spearman correlation :0.6606060606060605=================\n",
      "tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') tensor([[ 0, 20,  5,  ...,  1,  1,  1]], device='cuda:0') [tensor([55], device='cuda:0')] tensor([0.9820], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m sys.argv = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m--config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconfig/training_config.yaml\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# or 48shot_config.yaml\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m--model_seed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/fine-tune_plm/./confit/train.py:191\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    188\u001b[39m best_epoch = \u001b[32m0\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mmax_epochs\u001b[39m\u001b[33m'\u001b[39m])):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlambda_reg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     accelerator.print(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m========epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; training loss :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=================\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    193\u001b[39m     sr = evaluate(model, valloader, tokenizer, accelerator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/fine-tune_plm/./confit/train.py:48\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, model_reg, trainloder, optimizer, tokenizer, lambda_reg)\u001b[39m\n\u001b[32m     45\u001b[39m loss = l_BT + lambda_reg*l_reg\n\u001b[32m     47\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m optimizer.step()\n\u001b[32m     50\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sys.argv = [\n",
    "    \"train.py\",\n",
    "    \"--config\", \"config/training_config.yaml\",  # or 48shot_config.yaml\n",
    "    \"--dataset\", \"IF1_ECOLI_Kelsic2016_fitness_rich\",\n",
    "    \"--sample_seed\", \"0\",\n",
    "    \"--model_seed\", \"1\",\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e3c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e42daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv(\"data/IF1_ECOLI_Kelsic2016_fitness_rich/data.csv\")\n",
    "df_gened = pd.read_csv(\"data/IF1_ECOLI_Kelsic_2016/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76e6b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                                seq  log_fitness  \\\n",
       " 0           2  MTKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.010750   \n",
       " 1           3  MRKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.981167   \n",
       " 2           4  MSKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.009167   \n",
       " 3           5  MIKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.057333   \n",
       " 4           6  MMKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     1.035000   \n",
       " \n",
       "    n_mut mutant  PID  mutated_position  \n",
       " 0      1    A2T    2                 1  \n",
       " 1      1    A2R    3                 1  \n",
       " 2      1    A2S    4                 1  \n",
       " 3      1    A2I    5                 1  \n",
       " 4      1    A2M    6                 1  ,\n",
       "    Unnamed: 0                                                seq  log_fitness  \\\n",
       " 0           0  HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.147500   \n",
       " 1           1  GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...    -0.001750   \n",
       " 2           2  IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.118000   \n",
       " 3           3  LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.080333   \n",
       " 4           4  NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.407500   \n",
       " \n",
       "    PID  mutated_position mutant  \n",
       " 0    0                 0    M1H  \n",
       " 1    1                 0    M1G  \n",
       " 2    2                 0    M1I  \n",
       " 3    3                 0    M1L  \n",
       " 4    4                 0    M1N  )"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori.head(), df_gened.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c466b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness_x</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutant_x</th>\n",
       "      <th>PID_x</th>\n",
       "      <th>mutated_position_x</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>log_fitness_y</th>\n",
       "      <th>PID_y</th>\n",
       "      <th>mutated_position_y</th>\n",
       "      <th>mutant_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>MTKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.010750</td>\n",
       "      <td>1</td>\n",
       "      <td>A2T</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1.010750</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>A2T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>MRKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.981167</td>\n",
       "      <td>1</td>\n",
       "      <td>A2R</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.981167</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>A2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>MSKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.009167</td>\n",
       "      <td>1</td>\n",
       "      <td>A2S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1.009167</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>A2S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>MIKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.057333</td>\n",
       "      <td>1</td>\n",
       "      <td>A2I</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.057333</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>A2I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>MMKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>1</td>\n",
       "      <td>A2M</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A2M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1306</td>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.640250</td>\n",
       "      <td>1</td>\n",
       "      <td>R70V</td>\n",
       "      <td>1306</td>\n",
       "      <td>69</td>\n",
       "      <td>1324</td>\n",
       "      <td>0.640250</td>\n",
       "      <td>1324</td>\n",
       "      <td>69</td>\n",
       "      <td>R70V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>1307</td>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>1</td>\n",
       "      <td>R70Y</td>\n",
       "      <td>1307</td>\n",
       "      <td>69</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>1326</td>\n",
       "      <td>69</td>\n",
       "      <td>R70Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1308</td>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>1</td>\n",
       "      <td>R70C</td>\n",
       "      <td>1308</td>\n",
       "      <td>69</td>\n",
       "      <td>1328</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>1328</td>\n",
       "      <td>69</td>\n",
       "      <td>R70C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1309</td>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>1</td>\n",
       "      <td>R70W</td>\n",
       "      <td>1309</td>\n",
       "      <td>69</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>1325</td>\n",
       "      <td>69</td>\n",
       "      <td>R70W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>1310</td>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>1</td>\n",
       "      <td>R70F</td>\n",
       "      <td>1310</td>\n",
       "      <td>69</td>\n",
       "      <td>1312</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>1312</td>\n",
       "      <td>69</td>\n",
       "      <td>R70F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1206 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0_x                                                seq  \\\n",
       "0                2  MTKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "1                3  MRKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "2                4  MSKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "3                5  MIKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "4                6  MMKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "...            ...                                                ...   \n",
       "1201          1306  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "1202          1307  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "1203          1308  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "1204          1309  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "1205          1310  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...   \n",
       "\n",
       "      log_fitness_x  n_mut mutant_x  PID_x  mutated_position_x  Unnamed: 0_y  \\\n",
       "0          1.010750      1      A2T      2                   1            31   \n",
       "1          0.981167      1      A2R      3                   1            36   \n",
       "2          1.009167      1      A2S      4                   1            32   \n",
       "3          1.057333      1      A2I      5                   1            25   \n",
       "4          1.035000      1      A2M      6                   1            30   \n",
       "...             ...    ...      ...    ...                 ...           ...   \n",
       "1201       0.640250      1     R70V   1306                  69          1324   \n",
       "1202       0.373500      1     R70Y   1307                  69          1326   \n",
       "1203       0.598000      1     R70C   1308                  69          1328   \n",
       "1204       0.254000      1     R70W   1309                  69          1325   \n",
       "1205       0.294500      1     R70F   1310                  69          1312   \n",
       "\n",
       "      log_fitness_y  PID_y  mutated_position_y mutant_y  \n",
       "0          1.010750     31                   1      A2T  \n",
       "1          0.981167     36                   1      A2R  \n",
       "2          1.009167     32                   1      A2S  \n",
       "3          1.057333     25                   1      A2I  \n",
       "4          1.035000     30                   1      A2M  \n",
       "...             ...    ...                 ...      ...  \n",
       "1201       0.640250   1324                  69     R70V  \n",
       "1202       0.373500   1326                  69     R70Y  \n",
       "1203       0.598000   1328                  69     R70C  \n",
       "1204       0.254000   1325                  69     R70W  \n",
       "1205       0.294500   1312                  69     R70F  \n",
       "\n",
       "[1206 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori.merge(df_gened, on=\"seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0fe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b61f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='config/training_config.yaml', dataset='BRCA1_HUMAN_Fields2015-e3', sample_seed=0, model_seed=1)\n",
      "===================dataset:BRCA1_HUMAN_Fields2015-e3, preparing data=============\n",
      "                                                 seq  log_fitness  n_mut  \\\n",
      "0  MDLSALRVEEVQNVIAAMQKILECPICLELIKEPVSTKCDHIFCKF...     0.908475      1   \n",
      "1  MDLSALRVEEVQNVICAMQKILECPICLELIKEPVSTKCDHIFCKF...     0.156238      1   \n",
      "2  MDLSALRVEEVQNVIEAMQKILECPICLELIKEPVSTKCDHIFCKF...     1.287431      1   \n",
      "3  MDLSALRVEEVQNVIDAMQKILECPICLELIKEPVSTKCDHIFCKF...     1.074311      1   \n",
      "4  MDLSALRVEEVQNVIGAMQKILECPICLELIKEPVSTKCDHIFCKF...     1.177073      1   \n",
      "\n",
      "  mutant  PID  mutated_position  \n",
      "0   N16A    0                15  \n",
      "1   N16C    1                15  \n",
      "2   N16E    2                15  \n",
      "3   N16D    3                15  \n",
      "4   N16G    4                15  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# import argparse\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# class MockArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# args = MockArgs()\u001b[39;00m\n\u001b[32m     12\u001b[39m sys.argv = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m--config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconfig/training_config.yaml\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# or 48shot_config.yaml\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m--model_seed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/fine-tune_plm/./confit/train.py:157\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# sample data\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m accelerator.is_main_process:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[43msample_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshot\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     split_train(dataset)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m accelerator.main_process_first():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/fine-tune_plm/./confit/data_utils.py:66\u001b[39m, in \u001b[36msample_data\u001b[39m\u001b[34m(dataset_name, seed, shot, frac)\u001b[39m\n\u001b[32m     64\u001b[39m data = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/data.csv\u001b[39m\u001b[33m'\u001b[39m, index_col=\u001b[32m0\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.head())\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m test_data = data.sample(frac=frac, random_state=seed)\n\u001b[32m     68\u001b[39m train_data = data.drop(test_data.index)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "\n",
    "# class MockArgs:\n",
    "#     def __init__(self):\n",
    "#         self.dataset = \"IF1_ECOLI_Kelsic_2016\"\n",
    "#         self.model = \"ESM-1b\"\n",
    "#         self.sample_seed = 0  \n",
    "#         self.model_seed = 1  \n",
    "\n",
    "# args = MockArgs()\n",
    "\n",
    "sys.argv = [\n",
    "    \"train.py\",\n",
    "    \"--config\", \"config/training_config.yaml\",  # or 48shot_config.yaml\n",
    "    \"--dataset\", \"BRCA1_HUMAN_Fields2015-e3\",\n",
    "    \"--sample_seed\", \"0\",\n",
    "    \"--model_seed\", \"1\",\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1d97c",
   "metadata": {},
   "source": [
    "### Prepare Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dd9bfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f2790cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"facebook/esm1b_t33_650M_UR50S\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm1b_t33_650M_UR50S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a15e6765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# export HF_HOME=/work/commons/huggingface/hub\n",
    "\n",
    "# \"facebook/esm1v_t33_650M_UR90S_1\" not working\n",
    "\n",
    "from transformers import EsmForMaskedLM, EsmTokenizer\n",
    "\n",
    "model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "model = EsmForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "seq_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d40820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e068c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec146d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "      <th>mutant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M1H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M1G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>M1I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.080333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>M1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>1362</td>\n",
       "      <td>72</td>\n",
       "      <td>R72S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>1363</td>\n",
       "      <td>72</td>\n",
       "      <td>R72T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.904750</td>\n",
       "      <td>1364</td>\n",
       "      <td>72</td>\n",
       "      <td>R72V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.853500</td>\n",
       "      <td>1365</td>\n",
       "      <td>72</td>\n",
       "      <td>R72D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>1366</td>\n",
       "      <td>72</td>\n",
       "      <td>R72Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1367 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    seq  log_fitness   PID  \\\n",
       "0     HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.147500     0   \n",
       "1     GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...    -0.001750     1   \n",
       "2     IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.118000     2   \n",
       "3     LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.080333     3   \n",
       "4     NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.407500     4   \n",
       "...                                                 ...          ...   ...   \n",
       "1362  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.923333  1362   \n",
       "1363  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.911000  1363   \n",
       "1364  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.904750  1364   \n",
       "1365  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.853500  1365   \n",
       "1366  MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIR...     0.862500  1366   \n",
       "\n",
       "      mutated_position mutant  \n",
       "0                    1    M1H  \n",
       "1                    1    M1G  \n",
       "2                    1    M1I  \n",
       "3                    1    M1L  \n",
       "4                    1    M1N  \n",
       "...                ...    ...  \n",
       "1362                72   R72S  \n",
       "1363                72   R72T  \n",
       "1364                72   R72V  \n",
       "1365                72   R72D  \n",
       "1366                72   R72Y  \n",
       "\n",
       "[1367 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e737ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seq', 'log_fitness', 'PID', 'mutated_position', 'mutant'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea2e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list(data[\"seq\"])\n",
    "fitness = torch.tensor(data[\"log_fitness\"].values, dtype=torch.float32)\n",
    "positions = [[int(p) for p in str(pos).split(',')] if isinstance(pos, str) else [pos] for pos in data['mutated_position']]\n",
    "pids = data[\"PID\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46953e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367, 1367, 1367, 1367)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences), len(fitness), len(positions), len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8203b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d4152e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/IF1_ECOLI_Kelsic_2016/wt.fasta'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1be651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR\n"
     ]
    }
   ],
   "source": [
    "for seq_record in SeqIO.parse(wt_path, \"fasta\"):\n",
    "    wt = str(seq_record.seq)\n",
    "    print(wt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21e021",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c50ac39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutation_Set(Dataset):\n",
    "    def __init__(self, data, fname, tokenizer, sep_len=1024):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = sep_len\n",
    "        print(len(self.data['seq']))\n",
    "        self.seq, self.attention_mask = tokenizer(list(self.data['seq']), padding='max_length',\n",
    "                                                  truncation=True,\n",
    "                                                  max_length=self.seq_len).values()\n",
    "        # print(\"b\")\n",
    "        wt_path = os.path.join('data', fname, 'wt.fasta')\n",
    "        for seq_record in SeqIO.parse(wt_path, \"fasta\"):\n",
    "            wt = str(seq_record.seq)\n",
    "        target = [wt]*len(self.data)\n",
    "        self.target, self.tgt_mask = tokenizer(target, padding='max_length', truncation=True,\n",
    "                                               max_length=self.seq_len).values()\n",
    "        self.score = torch.tensor(np.array(self.data['log_fitness']))\n",
    "        self.pid = np.asarray(data['PID'])\n",
    "\n",
    "        if type(list(self.data['mutated_position'])[0]) != str:\n",
    "            self.position = [[u] for u in self.data['mutated_position']]\n",
    "\n",
    "        else:\n",
    "\n",
    "            temp = [u.split(',') for u in self.data['mutated_position']]\n",
    "            self.position = []\n",
    "            for u in temp:\n",
    "                pos = [int(v) for v in u]\n",
    "                self.position.append(pos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.seq[idx], self.attention_mask[idx], self.target[idx],self.tgt_mask[idx] ,self.position[idx], self.score[idx], self.pid[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.score)\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        seq = torch.tensor(np.array([u[0] for u in data]))\n",
    "        att_mask = torch.tensor(np.array([u[1] for u in data]))\n",
    "        tgt = torch.tensor(np.array([u[2] for u in data]))\n",
    "        tgt_mask = torch.tensor(np.array([u[3] for u in data]))\n",
    "        pos = [torch.tensor(u[4]) for u in data]\n",
    "        score = torch.tensor(np.array([u[5] for u in data]), dtype=torch.float32)\n",
    "        pid = torch.tensor(np.array([u[6] for u in data]))\n",
    "        return seq, att_mask, tgt, tgt_mask, pos, score, pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ddde2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Mutation_Set(data, dataset_name, tokenizer, sep_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40c90f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1367)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.attention_mask[0]), len(dataset.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f65c15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(dataset_name, seed, shot, frac=0.2):\n",
    "    '''\n",
    "    sample the train data and test data\n",
    "    :param seed: sample seed\n",
    "    :param frac: the fraction of testing data, default to 0.2\n",
    "    :param shot: the size of training data\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(f'data/{dataset_name}/data.csv')\n",
    "    # data = data.reindex()\n",
    "    test_data = data.sample(frac=frac, random_state=seed)\n",
    "    train_data = data.drop(test_data.index)\n",
    "    \n",
    "    # low-N training\n",
    "    # prepares the few labeled mutants for fine-tuning while leaving the rest for testing or validation\n",
    "    kshot_data = train_data.sample(n=shot, random_state=seed)\n",
    "    \n",
    "    assert len(kshot_data) == shot, (\n",
    "        f'expected {shot} train examples, received {len(train_data)}')\n",
    "\n",
    "    kshot_data.to_csv(f'data/{dataset_name}/train.csv')\n",
    "    test_data.to_csv(f'data/{dataset_name}/test.csv')\n",
    "\n",
    "\n",
    "def split_train(dataset_name):\n",
    "    '''\n",
    "    five equal split training data, one of which will be used as validation set when training ConFit\n",
    "    '''\n",
    "    train = pd.read_csv(f'data/{dataset_name}/train.csv')\n",
    "    tlen = int(np.ceil(len(train) / 5))\n",
    "    start = 0\n",
    "    for i in range(1, 5):\n",
    "        csv = train[start:start + tlen]\n",
    "        start += tlen\n",
    "        csv.to_csv(f'data/{dataset_name}/train_{i}.csv')\n",
    "    csv = train[start:]\n",
    "    csv.to_csv(f'data/{dataset_name}/train_{5}.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def spearman(y_pred, y_true):\n",
    "    if np.var(y_pred) < 1e-6 or np.var(y_true) < 1e-6:\n",
    "        return 0.0\n",
    "    return spearmanr(y_pred, y_true)[0]\n",
    "\n",
    "def compute_stat(sr):\n",
    "    sr = np.asarray(sr)\n",
    "    mean = np.mean(sr)\n",
    "    std = np.std(sr)\n",
    "    sr = (sr,)\n",
    "    ci = list(bootstrap(sr, np.mean).confidence_interval)\n",
    "    return mean, std, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "557be2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BT_loss(scores, golden_score):\n",
    "    loss = torch.tensor(0.)\n",
    "    loss = loss.cuda()\n",
    "    for i in range(len(scores)):\n",
    "        for j in range(i, len(scores)):\n",
    "            if golden_score[i] > golden_score[j]:\n",
    "                loss += torch.log(1+torch.exp(scores[j]-scores[i]))\n",
    "            else:\n",
    "                loss += torch.log(1+torch.exp(scores[i]-scores[j]))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def KLloss(logits, logits_reg, seq, att_mask):\n",
    "\n",
    "    creterion_reg = torch.nn.KLDivLoss(reduction='mean')\n",
    "    batch_size = int(seq.shape[0])\n",
    "\n",
    "    loss = torch.tensor(0.)\n",
    "    loss = loss.cuda()\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    probs_reg = torch.softmax(logits_reg, dim=-1)\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        probs_i = probs[i]\n",
    "        probs_reg_i = probs_reg[i]\n",
    "\n",
    "\n",
    "        seq_len = torch.sum(att_mask[i])\n",
    "\n",
    "        reg = probs_reg_i[torch.arange(0, seq_len), seq[i, :seq_len]]\n",
    "        pred = probs_i[torch.arange(0, seq_len), seq[i, :seq_len]]\n",
    "\n",
    "        loss += creterion_reg(reg.log(), pred)\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, testloader, tokenizer, accelerator, istest=False):\n",
    "    model.eval()\n",
    "    seq_list = []\n",
    "    score_list = []\n",
    "    gscore_list = []\n",
    "    device = next(model.parameters()).device  # Get model's device (e.g., 'cuda:0')\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(testloader):\n",
    "            seq, mask = data[0].to(device), data[1].to(device)\n",
    "            wt, wt_mask = data[2].to(device), data[3].to(device)\n",
    "            pos = [p.to(device) for p in data[4]]\n",
    "            golden_score = data[5].to(device)\n",
    "            pid = data[6].to(device)\n",
    "            if istest:\n",
    "                if accelerator is not None:\n",
    "                    pid = accelerator.gather(pid)\n",
    "                for s in pid:\n",
    "                    seq_list.append(s.cpu())\n",
    "\n",
    "            score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "\n",
    "            if accelerator is not None:\n",
    "                score = accelerator.gather(score)\n",
    "                golden_score = accelerator.gather(golden_score)\n",
    "            score = np.asarray(score.cpu())\n",
    "            golden_score = np.asarray(golden_score.cpu())\n",
    "            score_list.extend(score)\n",
    "            gscore_list.extend(golden_score)\n",
    "    score_list = np.asarray(score_list)\n",
    "    gscore_list = np.asarray(gscore_list)\n",
    "    sr = spearman(score_list, gscore_list)\n",
    "\n",
    "    if istest:\n",
    "        seq_list = np.asarray(seq_list)\n",
    "\n",
    "        return sr, score_list, seq_list\n",
    "    else:\n",
    "        return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1919690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training size\n",
    "shot = 100\n",
    "seed = 0\n",
    "sample_data(dataset_name, seed, shot)\n",
    "split_train(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a880d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f'data/{dataset_name}/train.csv', index_col=0)\n",
    "val_data = pd.read_csv(f'data/{dataset_name}/train_1.csv', index_col=0)\n",
    "test_data = pd.read_csv(f'data/{dataset_name}/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94d8b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Mutation_Set(train_data, dataset_name, tokenizer, sep_len=seq_len)\n",
    "val_dataset = Mutation_Set(val_data, dataset_name, tokenizer, sep_len=seq_len)\n",
    "test_dataset = Mutation_Set(test_data, dataset_name, tokenizer, sep_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "390a073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          collate_fn=train_dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False,\n",
    "                        collate_fn=val_dataset.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False,\n",
    "                         collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a5cfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58a5b789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, torch.Size([2, 1024]), torch.Size([2, 1024]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch), batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ab68e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,027,520 || all params: 654,384,054 || trainable%: 0.3098364007506821\n"
     ]
    }
   ],
   "source": [
    "base_model = model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=None,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"key\", \"value\"])\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3504fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"facebook/esm2_t48_15B_UR50D\"\n",
    "# base_model = EsmForMaskedLM.from_pretrained(model_name, \n",
    "#                                             torch_dtype=torch.float16,\n",
    "#                                             # low_cpy_mem_usage=True,\n",
    "#                                             use_auth_token=True)\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     r=8,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     target_modules=[\"query\", \"value\"])\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d62332a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): EsmForMaskedLM(\n",
       "      (esm): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-32): 33 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (lm_head): EsmLMHead(\n",
       "        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=1280, out_features=33, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "accelerator = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "lambda_reg = 0.1\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 33])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute_score() missing 2 required positional arguments: 'spurs_ddg' and 'aa_token_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(logits.shape)\n\u001b[32m     15\u001b[39m exit()   \n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m score, logits = \u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m l_bt = BT_loss(score, golden_score)\n\u001b[32m     19\u001b[39m l_reg = KLloss(logits, logits, seq, mask)\n",
      "\u001b[31mTypeError\u001b[39m: compute_score() missing 2 required positional arguments: 'spurs_ddg' and 'aa_token_ids'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# IF1\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        seq, mask, wt, wt_mask, pos, golden_score, pid = batch\n",
    "        seq, mask, wt, wt_mask, golden_score, pid = seq.to(device), mask.to(device), wt.to(device), wt_mask.to(device), golden_score.to(device), pid.to(device)\n",
    "        pos = [p.to(device) for p in pos]\n",
    "        \n",
    "        out = model(seq, attention_mask=mask, output_hidden_states=True)\n",
    "        logits = out.logits\n",
    "        print(logits.shape)\n",
    "        exit()   \n",
    "        \n",
    "        score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "        l_bt = BT_loss(score, golden_score)\n",
    "        l_reg = KLloss(logits, logits, seq, mask)\n",
    "        loss = l_bt + lambda_reg * l_reg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {total_loss / len(train_loader)}')\n",
    "    \n",
    "    val_sr = evaluate(model, val_loader, tokenizer, None)\n",
    "    print(f'Epoch {epoch + 1}, Validation Spearman: {val_sr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7844d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/functional.py:3355: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 3.1181334543228147\n",
      "Epoch 1, Validation Spearman: 0.6827067669172932\n",
      "Epoch 2, Training Loss: 2.144273052215576\n",
      "Epoch 2, Validation Spearman: 0.7954887218045112\n",
      "Epoch 3, Training Loss: 2.174126436710358\n",
      "Epoch 3, Validation Spearman: 0.7744360902255639\n",
      "Epoch 4, Training Loss: 2.3140823149681093\n",
      "Epoch 4, Validation Spearman: 0.7909774436090224\n",
      "Epoch 5, Training Loss: 2.3498859095573423\n",
      "Epoch 5, Validation Spearman: 0.7984962406015037\n"
     ]
    }
   ],
   "source": [
    "# BR\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        seq, mask, wt, wt_mask, pos, golden_score, pid = batch\n",
    "        seq, mask, wt, wt_mask, golden_score, pid = seq.to(device), mask.to(device), wt.to(device), wt_mask.to(device), golden_score.to(device), pid.to(device)\n",
    "        pos = [p.to(device) for p in pos]\n",
    "        score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "        l_bt = BT_loss(score, golden_score)\n",
    "        l_reg = KLloss(logits, logits, seq, mask)\n",
    "        loss = l_bt + lambda_reg * l_reg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {total_loss / len(train_loader)}')\n",
    "    \n",
    "    val_sr = evaluate(model, val_loader, tokenizer, None)\n",
    "    print(f'Epoch {epoch + 1}, Validation Spearman: {val_sr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e11af946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b6819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71555633",
   "metadata": {},
   "source": [
    "## Integrate with SPURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0398fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af3e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/work/yunan/PsiFit/data/proteingym\")\n",
    "datasets = [d.name for d in base_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "data = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    fasta_path = base_dir / dataset / \"wildtype.fasta\"\n",
    "    if fasta_path.exists():\n",
    "        try:\n",
    "            record = next(SeqIO.parse(fasta_path, \"fasta\"))\n",
    "            seq = str(record.seq)\n",
    "            length = len(seq)\n",
    "            data.append({'dms_id': dataset, 'seq_length': length})\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {fasta_path}: {e}\")\n",
    "            \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.sort_values(by='seq_length', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b115e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_id</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VG08_BPP22_Tsuboyama_2023_2GP8</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>SQSTM_MOUSE_Tsuboyama_2023_2RRU</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>OTU7A_HUMAN_Tsuboyama_2023_2L2D</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HCP_LAMBD_Tsuboyama_2023_2L6Q</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DN7A_SACS2_Tsuboyama_2023_1JIC</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NPC1_HUMAN_Erwood_2022_RPE1</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NPC1_HUMAN_Erwood_2022_HEK293T</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>BRCA1_HUMAN_Findlay_2018</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SCN5A_HUMAN_Glazer_2019</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>POLG_CXB3N_Mattenberger_2021</td>\n",
       "      <td>2185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              dms_id  seq_length\n",
       "50    VG08_BPP22_Tsuboyama_2023_2GP8          40\n",
       "65   SQSTM_MOUSE_Tsuboyama_2023_2RRU          40\n",
       "139  OTU7A_HUMAN_Tsuboyama_2023_2L2D          42\n",
       "25     HCP_LAMBD_Tsuboyama_2023_2L6Q          55\n",
       "6     DN7A_SACS2_Tsuboyama_2023_1JIC          55\n",
       "..                               ...         ...\n",
       "39       NPC1_HUMAN_Erwood_2022_RPE1        1278\n",
       "118   NPC1_HUMAN_Erwood_2022_HEK293T        1278\n",
       "84          BRCA1_HUMAN_Findlay_2018        1863\n",
       "117          SCN5A_HUMAN_Glazer_2019        2016\n",
       "26      POLG_CXB3N_Mattenberger_2021        2185\n",
       "\n",
       "[142 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0a10b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_id</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>ENVZ_ECOLI_Ghose_2023</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>IF1_ECOLI_Kelsic_2016</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>TAT_HV1BR_Fernandes_2016</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A0A247D711_LISMN_Stadelmann_2021</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CCDB_ECOLI_Tripathi_2016</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NPC1_HUMAN_Erwood_2022_RPE1</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NPC1_HUMAN_Erwood_2022_HEK293T</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>BRCA1_HUMAN_Findlay_2018</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SCN5A_HUMAN_Glazer_2019</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>POLG_CXB3N_Mattenberger_2021</td>\n",
       "      <td>2185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dms_id  seq_length\n",
       "110             ENVZ_ECOLI_Ghose_2023          60\n",
       "91              IF1_ECOLI_Kelsic_2016          72\n",
       "93           TAT_HV1BR_Fernandes_2016          86\n",
       "47   A0A247D711_LISMN_Stadelmann_2021          87\n",
       "32           CCDB_ECOLI_Tripathi_2016         101\n",
       "..                                ...         ...\n",
       "39        NPC1_HUMAN_Erwood_2022_RPE1        1278\n",
       "118    NPC1_HUMAN_Erwood_2022_HEK293T        1278\n",
       "84           BRCA1_HUMAN_Findlay_2018        1863\n",
       "117           SCN5A_HUMAN_Glazer_2019        2016\n",
       "26       POLG_CXB3N_Mattenberger_2021        2185\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['dms_id'].str.contains('Tsuboyama')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c0ed827",
   "metadata": {},
   "outputs": [],
   "source": [
    "dms_id = \"IF1_ECOLI_Kelsic_2016\"\n",
    "# dms_id = \"IF1_ECOLI_Kelsic_2016\"\n",
    "spurs_path = base_dir / dms_id / \"spurs_prediction.tsv\"\n",
    "spurs_df = pd.read_csv(spurs_path, sep='\\t', index_col=0)\n",
    "spurs_ddg = torch.tensor(spurs_df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f81b8ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
       "       'R', 'S', 'T', 'V', 'W', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spurs_df.head()\n",
    "spurs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76a4d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = next(SeqIO.parse(base_dir / dms_id / \"wildtype.fasta\", \"fasta\"))\n",
    "wt_seq = str(wt.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "510c2dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48389651",
   "metadata": {},
   "source": [
    "#### PsiFit Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05973775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EsmForMaskedLM, EsmTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14072c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "esm_model = EsmForMaskedLM.from_pretrained(model_name)\n",
    "esm_tokenizer = EsmTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f6b1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_list = list(\"ACDEFGHIKLMNPQRSTVWY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fa210a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spurs_df.columns.tolist() == aa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "136507e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM natural amino acid order: ['L', 'A', 'G', 'V', 'S', 'E', 'R', 'T', 'I', 'D', 'P', 'K', 'Q', 'N', 'F', 'Y', 'M', 'H', 'W', 'C', 'X', 'B', 'U', 'Z', 'O']\n"
     ]
    }
   ],
   "source": [
    "# esm natural aa order\n",
    "vocab = esm_tokenizer.get_vocab()\n",
    "aa_tokens_sorted = sorted((v, k) for k, v in vocab.items() if len(k) == 1 and k.isupper())\n",
    "print(\"ESM natural amino acid order:\", [t[1] for t in aa_tokens_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a8037972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_list == [t[1] for t in aa_tokens_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6afbb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = spurs_df.index.tolist()\n",
    "esm_probs_df =  pd.DataFrame(index=positions, columns=aa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "57a01792",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_token_ids = [esm_tokenizer.convert_tokens_to_ids(aa) for aa in aa_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e583c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token = esm_tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ff4a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "639e6abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmForMaskedLM(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-32): 33 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): EsmLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=1280, out_features=33, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "esm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ab6edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PsiFit(nn.Module):\n",
    "    def __init__(self, esm_model, spurs_ddg, aa_token_ids):\n",
    "        super(PsiFit, self).__init__()\n",
    "        self.esm = esm_model\n",
    "        self.A = nn.Parameter(torch.tensor(0.1))\n",
    "        self.b = nn.Parameter(torch.tensor(0.1))\n",
    "        \n",
    "        self.A2 = nn.Parameter(torch.tensor(0.1))\n",
    "        self.b2 = nn.Parameter(torch.tensor(0.1))\n",
    "        \n",
    "        self.spurs_ddg = spurs_ddg.to(device)\n",
    "        self.aa_token_ids = aa_token_ids\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.esm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        seq_len = input_ids.shape[1] - 2\n",
    "        aligned_ddg = self.spurs_ddg.unsqueeze(0).to(logits.device)\n",
    "        scaled_ddg = self.A * aligned_ddg + self.b\n",
    "        \n",
    "        aligned_logits = logits[:, 1:seq_len+1, self.aa_token_ids]\n",
    "        adjusted_logits = aligned_logits + scaled_ddg\n",
    "        \n",
    "        aligned_logits = self.A2 * adjusted_logits + self.b2\n",
    "        \n",
    "        logits[:, 1:seq_len+1, self.aa_token_ids] = aligned_logits\n",
    "        outputs.logits = logits\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4e532bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_reg, trainloader, optimizer, tokenizer, lambda_reg):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for step, data in enumerate(trainloader):\n",
    "        seq, mask = data[0], data[1]\n",
    "        wt, wt_mask = data[2], data[3]\n",
    "        pos = data[4]\n",
    "        golden_score = data[5]\n",
    "        score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "        score = score.cuda()\n",
    "        l_BT = BT_loss(score, golden_score)\n",
    "        out_reg = model_reg(wt, wt_mask)\n",
    "        logits_reg = out_reg.logits\n",
    "        l_reg = KLloss(logits, logits_reg, seq, mask)\n",
    "        loss = l_BT + lambda_reg * l_reg\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def evaluate(model, testloader, tokenizer, accelerator, istest=False):\n",
    "    model.eval()\n",
    "    seq_list = []\n",
    "    score_list = []\n",
    "    gscore_list = []\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(testloader):\n",
    "            seq, mask = data[0], data[1]\n",
    "            wt, wt_mask = data[2], data[3]\n",
    "            pos = data[4]\n",
    "            golden_score = data[5]\n",
    "            pid = data[6]\n",
    "            if istest:\n",
    "                pid = pid.cuda()\n",
    "                pid = accelerator.gather(pid)\n",
    "                for s in pid:\n",
    "                    seq_list.append(s.cpu())\n",
    "            score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "            score = score.cuda()\n",
    "            score = accelerator.gather(score)\n",
    "            golden_score = accelerator.gather(golden_score)\n",
    "            score = np.asarray(score.cpu())\n",
    "            golden_score = np.asarray(golden_score.cpu())\n",
    "            score_list.extend(score)\n",
    "            gscore_list.extend(golden_score)\n",
    "    score_list = np.asarray(score_list)\n",
    "    gscore_list = np.asarray(gscore_list)\n",
    "    sr = spearman(score_list, gscore_list)\n",
    "    if istest:\n",
    "        seq_list = np.asarray(seq_list)\n",
    "        return sr, score_list, seq_list\n",
    "    else:\n",
    "        return sr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ef02bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PsiFit(\n",
       "  (esm): EsmForMaskedLM(\n",
       "    (esm): EsmModel(\n",
       "      (embeddings): EsmEmbeddings(\n",
       "        (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "      )\n",
       "      (encoder): EsmEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-32): 33 x EsmLayer(\n",
       "            (attention): EsmAttention(\n",
       "              (self): EsmSelfAttention(\n",
       "                (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (rotary_embeddings): RotaryEmbedding()\n",
       "              )\n",
       "              (output): EsmSelfOutput(\n",
       "                (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (intermediate): EsmIntermediate(\n",
       "              (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            )\n",
       "            (output): EsmOutput(\n",
       "              (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (contact_head): EsmContactPredictionHead(\n",
       "        (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (lm_head): EsmLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (decoder): Linear(in_features=1280, out_features=33, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psifit = PsiFit(esm_model, spurs_ddg, aa_token_ids)\n",
    "psifit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "119ab19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PsiFit(\n",
       "  (esm): EsmForMaskedLM(\n",
       "    (esm): EsmModel(\n",
       "      (embeddings): EsmEmbeddings(\n",
       "        (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "      )\n",
       "      (encoder): EsmEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-32): 33 x EsmLayer(\n",
       "            (attention): EsmAttention(\n",
       "              (self): EsmSelfAttention(\n",
       "                (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (rotary_embeddings): RotaryEmbedding()\n",
       "              )\n",
       "              (output): EsmSelfOutput(\n",
       "                (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (intermediate): EsmIntermediate(\n",
       "              (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            )\n",
       "            (output): EsmOutput(\n",
       "              (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (contact_head): EsmContactPredictionHead(\n",
       "        (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (lm_head): EsmLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (decoder): Linear(in_features=1280, out_features=33, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psifit.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48d22adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(psifit.parameters(), lr=1e-5)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e49eeb",
   "metadata": {},
   "source": [
    "#### Vanilla loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Avg Loss 2.0279\n",
      "Epoch 2: Avg Loss 0.5987\n",
      "Epoch 3: Avg Loss 0.1215\n",
      "Epoch 4: Avg Loss 0.0298\n",
      "Epoch 5: Avg Loss 0.0086\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for idx, pos in enumerate(positions):\n",
    "        seq_list = list(wt_seq)\n",
    "        seq_list[pos - 1] = mask_token \n",
    "        masked_seq = ''.join(seq_list)\n",
    "        \n",
    "        inputs = esm_tokenizer(masked_seq, return_tensors='pt').to(device)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        labels = input_ids.clone()\n",
    "        labels[:, :] = -100  \n",
    "        orig_token_id = esm_tokenizer.convert_tokens_to_ids(wt_seq[pos - 1])\n",
    "        labels[:, pos] = orig_token_id  \n",
    "        \n",
    "        outputs = psifit(input_ids, attention_mask, labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Avg Loss {total_loss / len(positions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd93f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_dir = Path(\"/work/yunan/PsiFit/data/proteingym\")\n",
    "\n",
    "def data_restruct(dms_id, input_dir=Path(\"/work/yunan/PsiFit/data/proteingym\"), output_base=Path(\"./data\")):\n",
    "    wt_seq = str(next(SeqIO.parse(input_dir / dms_id / \"wildtype.fasta\", \"fasta\")).seq)\n",
    "    df = pd.read_csv(input_dir / dms_id / \"proteingym_dms.tsv\", sep='\\t')\n",
    "    output_dms_dir = output_base / dms_id\n",
    "    os.makedirs(output_dms_dir, exist_ok=True)\n",
    "    \n",
    "    shutil.copy(input_dir / dms_id / \"wildtype.fasta\", output_dms_dir / \"wt.fasta\")\n",
    "    \n",
    "    if 'mutated_sequence' not in df.columns:\n",
    "        def apply_mutations(mutant):\n",
    "            seq_list = list(wt_seq)\n",
    "            mutations = mutant.split(':')\n",
    "            for mut in mutations:\n",
    "                if len(mut) < 3:\n",
    "                    raise ValueError(f\"Invalid mutant format: {mut}\")\n",
    "                wild_aa, pos_str, mut_aa = mut[0], mut[1:-1], mut[-1]\n",
    "                pos = int(pos_str)\n",
    "                if seq_list[pos - 1] != wild_aa:\n",
    "                    raise ValueError(f\"Mismatch at position {pos}: expected {wild_aa}, found {seq_list[pos - 1]}\")\n",
    "                seq_list[pos - 1] = mut_aa\n",
    "            return ''.join(seq_list)\n",
    "        df['mutated_sequence'] = df['mutant'].apply(apply_mutations)\n",
    "        \n",
    "    df = df.rename(columns={'mutated_sequence': 'seq', 'DMS_score': 'log_fitness'})\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    def extract_positions(mutant):\n",
    "        positions = [int(mut[1:-1])-1 for mut in mutant.split(':')]\n",
    "        if len(positions) == 1:\n",
    "            return positions[0]\n",
    "        else:\n",
    "            return ','.join(map(str, positions))\n",
    "    df['mutated_position'] = df['mutant'].apply(extract_positions)\n",
    "    \n",
    "    df['PID'] = df.index.astype(str)\n",
    "    \n",
    "    relevant_cols = ['seq', 'log_fitness', 'PID', 'mutated_position', 'mutant']\n",
    "    df = df[relevant_cols]\n",
    "    \n",
    "    df.to_csv(output_dms_dir / \"test.csv\", index=True)\n",
    "    df.to_csv(output_dms_dir / \"data.csv\", index=True)\n",
    "    \n",
    "    print(f\"Prepared data for {dms_id} in {output_dms_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "964ba362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data for IF1_ECOLI_Kelsic_2016 in data/IF1_ECOLI_Kelsic_2016\n"
     ]
    }
   ],
   "source": [
    "data_restruct(\"IF1_ECOLI_Kelsic_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "883a81cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_fitness', 'PID', 'mutated_position', 'mutant'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c887890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "      <th>mutant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR</th>\n",
       "      <td>0.147500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M1H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR</th>\n",
       "      <td>-0.001750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M1G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR</th>\n",
       "      <td>0.118000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>M1I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR</th>\n",
       "      <td>0.080333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR</th>\n",
       "      <td>0.407500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>M1N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    log_fitness  PID  \\\n",
       "seq                                                                    \n",
       "HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...     0.147500    0   \n",
       "GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...    -0.001750    1   \n",
       "IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...     0.118000    2   \n",
       "LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...     0.080333    3   \n",
       "NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...     0.407500    4   \n",
       "\n",
       "                                                    mutated_position mutant  \n",
       "seq                                                                          \n",
       "HAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...                 1    M1H  \n",
       "GAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...                 1    M1G  \n",
       "IAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...                 1    M1I  \n",
       "LAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...                 1    M1L  \n",
       "NAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRI...                 1    M1N  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b70f9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "import yaml\n",
    "import torch.nn as nn\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "70ef9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 4, \n",
    "    'gpu_number': 4,\n",
    "    'lora_r': 8,\n",
    "    'lora_alpha': 16,\n",
    "    'lora_dropout': 0.1,\n",
    "    'ini_lr': 1e-4,\n",
    "    'min_lr': 1e-5,\n",
    "    'max_epochs': 10,\n",
    "    'lambda_reg': 0.1,\n",
    "    'shot': 48,\n",
    "    'endure_time': 3\n",
    "}\n",
    "\n",
    "dms_id = \"IF1_ECOLI_Kelsic_2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "050ebbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "sample_seed = 0\n",
    "model_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7f45d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmForMaskedLM(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-32): 33 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (value): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): EsmLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=1280, out_features=33, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = PsiFit(esm_model, spurs_ddg, aa_token_ids)\n",
    "model = esm_model\n",
    "\n",
    "model_reg = esm_model\n",
    "\n",
    "for pm in model_reg.parameters():\n",
    "    pm.requires_grad = False\n",
    "model_reg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "071fbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=config['lora_r'],\n",
    "    lora_alpha=config['lora_alpha'],\n",
    "    lora_dropout=config['lora_dropout'],\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")\n",
    "model = get_peft_model(esm_model, peft_config)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['ini_lr'])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=2 * config['max_epochs'], eta_min=config['min_lr'])\n",
    "\n",
    "model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n",
    "model_reg = accelerator.prepare(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "719ae787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data for IF1_ECOLI_Kelsic_2016 in data/IF1_ECOLI_Kelsic_2016\n"
     ]
    }
   ],
   "source": [
    "if accelerator.is_main_process:\n",
    "    data_restruct(dms_id)\n",
    "    sample_data(dms_id, sample_seed, config['shot'])\n",
    "    split_train(dms_id)\n",
    "\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45faf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "with accelerator.main_process_first():\n",
    "    train_csv = pd.DataFrame()\n",
    "    test_csv = pd.read_csv(f'data/{dms_id}/test.csv')\n",
    "    for i in range(1, 6):\n",
    "        temp_csv = pd.read_csv(f'data/{dms_id}/train_{i}.csv')\n",
    "        if i == model_seed:\n",
    "            val_csv = temp_csv\n",
    "        train_csv = pd.concat([train_csv, temp_csv], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "794b9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = esm_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed9744b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============data preparing done!================\n"
     ]
    }
   ],
   "source": [
    "trainset = Mutation_Set(data=train_csv, fname=dms_id, tokenizer=tokenizer)\n",
    "testset = Mutation_Set(data=test_csv, fname=dms_id, tokenizer=tokenizer)\n",
    "valset = Mutation_Set(data=val_csv, fname=dms_id, tokenizer=tokenizer)\n",
    "\n",
    "batch_size = config['batch_size'] // config['gpu_number']\n",
    "\n",
    "with accelerator.main_process_first():\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, collate_fn=trainset.collate_fn, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=2, collate_fn=testset.collate_fn)\n",
    "    valloader = DataLoader(valset, batch_size=2, collate_fn=testset.collate_fn)\n",
    "\n",
    "trainloader = accelerator.prepare(trainloader)\n",
    "testloader = accelerator.prepare(testloader)\n",
    "valloader = accelerator.prepare(valloader)\n",
    "\n",
    "print('==============data preparing done!================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7edadfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3111"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "41840e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========epoch 0; training loss :33.27433866262436=================\n",
      "========epoch 0; val spearman correlation :0.0=================\n",
      "========epoch 1; training loss :33.252182602882385=================\n",
      "========epoch 1; val spearman correlation :0.0=================\n",
      "========epoch 2; training loss :33.20938283205032=================\n",
      "========epoch 2; val spearman correlation :0.0=================\n",
      "========epoch 3; training loss :33.01101964712143=================\n",
      "========epoch 3; val spearman correlation :0.0=================\n",
      "========epoch 4; training loss :32.38614994287491=================\n",
      "========epoch 4; val spearman correlation :0.0=================\n",
      "========epoch 5; training loss :32.19690269231796=================\n",
      "========epoch 5; val spearman correlation :0.0=================\n",
      "========epoch 6; training loss :31.96081030368805=================\n",
      "========epoch 6; val spearman correlation :0.0=================\n",
      "========epoch 7; training loss :31.722372889518738=================\n",
      "========epoch 7; val spearman correlation :0.0=================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[151]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m best_epoch = \u001b[32m0\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mmax_epochs\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlambda_reg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m========epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; training loss :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=================\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m     sr = evaluate(model, valloader, tokenizer, accelerator)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, model_reg, trainloader, optimizer, tokenizer, lambda_reg)\u001b[39m\n\u001b[32m     10\u001b[39m score = score.cuda()\n\u001b[32m     11\u001b[39m l_BT = BT_loss(score, golden_score)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m out_reg = \u001b[43mmodel_reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m logits_reg = out_reg.logits\n\u001b[32m     14\u001b[39m l_reg = KLloss(logits, logits_reg, seq, mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:1008\u001b[39m, in \u001b[36mEsmForMaskedLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    999\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m   1000\u001b[39m \u001b[33;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m \u001b[33;03m    Used to hide legacy arguments that have been deprecated.\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1006\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mesm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1020\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1021\u001b[39m prediction_scores = \u001b[38;5;28mself\u001b[39m.lm_head(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:914\u001b[39m, in \u001b[36mEsmModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    905\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m    907\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    908\u001b[39m     input_ids=input_ids,\n\u001b[32m    909\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m    913\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    927\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:619\u001b[39m, in \u001b[36mEsmEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    608\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    609\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    610\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    616\u001b[39m         output_attentions,\n\u001b[32m    617\u001b[39m     )\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    629\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:551\u001b[39m, in \u001b[36mEsmLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    548\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    549\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:563\u001b[39m, in \u001b[36mEsmLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    561\u001b[39m attention_output_ln = \u001b[38;5;28mself\u001b[39m.LayerNorm(attention_output)\n\u001b[32m    562\u001b[39m intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output_ln)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:476\u001b[39m, in \u001b[36mEsmOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, input_tensor):\n\u001b[32m    475\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dense(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m     hidden_states = hidden_states + input_tensor\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best_sr = -np.inf\n",
    "endure = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(config['max_epochs']):\n",
    "    loss = train(model, model_reg, trainloader, optimizer, tokenizer, config['lambda_reg'])\n",
    "    print(f'========epoch {epoch}; training loss :{loss}=================')\n",
    "    sr = evaluate(model, valloader, tokenizer, accelerator)\n",
    "    print(f'========epoch {epoch}; val spearman correlation :{sr}=================')\n",
    "    scheduler.step()\n",
    "    if best_sr > sr:\n",
    "        endure += 1\n",
    "    else:\n",
    "        endure = 0\n",
    "        best_sr = sr\n",
    "        best_epoch = epoch\n",
    "        save_path = f'./checkpoint/{dms_id}/seed{model_seed}'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(save_path)\n",
    "    if sr == 1.0 or endure > config['endure_time']:\n",
    "        print(f'========early stop at epoch {epoch}!============')\n",
    "        break\n",
    "    \n",
    "print('=======training done!, test the performance!========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "11a05242",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PsiFit' object has no attribute 'prepare_inputs_for_generation'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/peft/tuners/lora/model.py:311\u001b[39m, in \u001b[36mLoraModel.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# defer to nn.Module's logic\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'LoraModel' object has no attribute 'prepare_inputs_for_generation'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[141]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m custom_basemodel = PsiFit(esm_model, spurs_ddg, aa_token_ids)\n\u001b[32m      5\u001b[39m save_path = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcheckpoint/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdms_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/seed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mPeftModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_basemodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model = accelerator.prepare(model)\n\u001b[32m      9\u001b[39m sr, score, pid = evaluate(model, testloader, tokenizer, accelerator, istest=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/peft/peft_model.py:355\u001b[39m, in \u001b[36mPeftModel.from_pretrained\u001b[39m\u001b[34m(cls, model, model_id, adapter_name, is_trainable, config, **kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m     model = \u001b[38;5;28mcls\u001b[39m(model, config, adapter_name)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     model = \u001b[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m model.load_adapter(model_id, adapter_name, is_trainable=is_trainable, **kwargs)\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/peft/peft_model.py:1095\u001b[39m, in \u001b[36mPeftModelForCausalLM.__init__\u001b[39m\u001b[34m(self, model, peft_config, adapter_name)\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: torch.nn.Module, peft_config: PeftConfig, adapter_name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1094\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(model, peft_config, adapter_name)\n\u001b[32m-> \u001b[39m\u001b[32m1095\u001b[39m     \u001b[38;5;28mself\u001b[39m.base_model_prepare_inputs_for_generation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_inputs_for_generation\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/peft/tuners/lora/model.py:313\u001b[39m, in \u001b[36mLoraModel.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattr__\u001b[39m(name)  \u001b[38;5;66;03m# defer to nn.Module's logic\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'PsiFit' object has no attribute 'prepare_inputs_for_generation'"
     ]
    }
   ],
   "source": [
    "del model\n",
    "accelerator.free_memory()\n",
    "\n",
    "custom_basemodel = PsiFit(esm_model, spurs_ddg, aa_token_ids)\n",
    "save_path = f'checkpoint/{dms_id}/seed{model_seed}'\n",
    "model = PeftModel.from_pretrained(custom_basemodel, save_path)\n",
    "model = accelerator.prepare(model)\n",
    "\n",
    "sr, score, pid = evaluate(model, testloader, tokenizer, accelerator, istest=True)\n",
    "pred_csv = pd.DataFrame({f'{model_seed}': score, 'PID': pid})\n",
    "os.makedirs(f'predicted/{dms_id}', exist_ok=True)\n",
    "if os.path.exists(f'predicted/{dms_id}/pred.csv'):\n",
    "    pred = pd.read_csv(f'predicted/{dms_id}/pred.csv', index_col=0)\n",
    "    pred = pd.merge(pred, pred_csv, on='PID')\n",
    "else:\n",
    "    pred = pred_csv\n",
    "pred.to_csv(f'predicted/{dms_id}/pred.csv')\n",
    "print(f'=============the test spearman correlation: {sr}==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2256817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a52a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08902b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c96fe4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
