{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ae55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccca6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39.3\n",
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import transformers\n",
    "import peft\n",
    "# print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(peft.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a5d23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab00834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, get_peft_model\n",
    "from peft.utils.other import fsdp_auto_wrap_policy\n",
    "from transformers import EsmForMaskedLM, EsmTokenizer, EsmConfig\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from confit.data_utils import Mutation_Set, split_train, sample_data\n",
    "from confit.stat_utils import spearman, compute_score, BT_loss, KLloss\n",
    "\n",
    "from Bio import SeqIO\n",
    "from transformers import EsmTokenizer\n",
    "\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6458a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers==4.39.3 peft==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7713972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"data/BRCA1_HUMAN_Fields2015-e3/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc972125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1271.000000</td>\n",
       "      <td>1271.000000</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>1271.000000</td>\n",
       "      <td>1271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>693.125098</td>\n",
       "      <td>0.546818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>693.125098</td>\n",
       "      <td>52.129819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>398.213603</td>\n",
       "      <td>0.484519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.213603</td>\n",
       "      <td>22.110417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.437145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>348.500000</td>\n",
       "      <td>0.237671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>348.500000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>697.000000</td>\n",
       "      <td>0.520609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>697.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1040.500000</td>\n",
       "      <td>0.834807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1040.500000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1381.000000</td>\n",
       "      <td>2.791509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  log_fitness   n_mut          PID  mutated_position\n",
       "count  1271.000000  1271.000000  1271.0  1271.000000       1271.000000\n",
       "mean    693.125098     0.546818     1.0   693.125098         52.129819\n",
       "std     398.213603     0.484519     0.0   398.213603         22.110417\n",
       "min       0.000000    -0.437145     1.0     0.000000         15.000000\n",
       "25%     348.500000     0.237671     1.0   348.500000         33.000000\n",
       "50%     697.000000     0.520609     1.0   697.000000         51.000000\n",
       "75%    1040.500000     0.834807     1.0  1040.500000         71.000000\n",
       "max    1381.000000     2.791509     1.0  1381.000000         90.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3e5fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutant</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutated_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MDLSALRVEEVQNVIAAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>0.908475</td>\n",
       "      <td>1</td>\n",
       "      <td>N16A</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MDLSALRVEEVQNVICAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>0.156238</td>\n",
       "      <td>1</td>\n",
       "      <td>N16C</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MDLSALRVEEVQNVIEAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>1.287431</td>\n",
       "      <td>1</td>\n",
       "      <td>N16E</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MDLSALRVEEVQNVIDAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>1.074311</td>\n",
       "      <td>1</td>\n",
       "      <td>N16D</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MDLSALRVEEVQNVIGAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>1.177073</td>\n",
       "      <td>1</td>\n",
       "      <td>N16G</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                seq  log_fitness  \\\n",
       "0           0  MDLSALRVEEVQNVIAAMQKILECPICLELIKEPVSTKCDHIFCKF...     0.908475   \n",
       "1           1  MDLSALRVEEVQNVICAMQKILECPICLELIKEPVSTKCDHIFCKF...     0.156238   \n",
       "2           2  MDLSALRVEEVQNVIEAMQKILECPICLELIKEPVSTKCDHIFCKF...     1.287431   \n",
       "3           3  MDLSALRVEEVQNVIDAMQKILECPICLELIKEPVSTKCDHIFCKF...     1.074311   \n",
       "4           4  MDLSALRVEEVQNVIGAMQKILECPICLELIKEPVSTKCDHIFCKF...     1.177073   \n",
       "\n",
       "   n_mut mutant  PID  mutated_position  \n",
       "0      1   N16A    0                15  \n",
       "1      1   N16C    1                15  \n",
       "2      1   N16E    2                15  \n",
       "3      1   N16D    3                15  \n",
       "4      1   N16G    4                15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2463f4",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915b9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"BRCA1_HUMAN_Fields2015-e3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1827e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f'data/{dataset_name}'\n",
    "data = pd.read_csv(f\"{data_dir}/data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0390d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wild type\n",
    "wt_path = f\"{data_dir}/wt.fasta\"\n",
    "wt_seq = str(next(SeqIO.parse(wt_path, \"fasta\")).seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f11514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild-type sequence length: 110\n"
     ]
    }
   ],
   "source": [
    "print(f'Wild-type sequence length: {len(wt_seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b4b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDLSALRVEEVQNVINAMQKILECPICLELIKEPVSTKCDHIFCKFCMLK\n"
     ]
    }
   ],
   "source": [
    "print(wt_seq[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15946bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VAE\n",
    "vae_elbo = pd.read_csv(f\"{data_dir}/vae_elbo.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e295be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>PID</th>\n",
       "      <th>elbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MDLSALRVEEVQNVIAAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDLSALRVEEVQNVICAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.123850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MDLSALRVEEVQNVIEAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDLSALRVEEVQNVIDAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.040975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDLSALRVEEVQNVIGAMQKILECPICLELIKEPVSTKCDHIFCKF...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.026119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  PID      elbo\n",
       "0  MDLSALRVEEVQNVIAAMQKILECPICLELIKEPVSTKCDHIFCKF...    0  0.629923\n",
       "1  MDLSALRVEEVQNVICAMQKILECPICLELIKEPVSTKCDHIFCKF...    1 -2.123850\n",
       "2  MDLSALRVEEVQNVIEAMQKILECPICLELIKEPVSTKCDHIFCKF...    2  0.151109\n",
       "3  MDLSALRVEEVQNVIDAMQKILECPICLELIKEPVSTKCDHIFCKF...    3 -0.040975\n",
       "4  MDLSALRVEEVQNVIGAMQKILECPICLELIKEPVSTKCDHIFCKF...    4 -1.026119"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_elbo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1d97c",
   "metadata": {},
   "source": [
    "### Prepare Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd9bfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2790cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"facebook/esm1b_t33_650M_UR50S\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm1b_t33_650M_UR50S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15e6765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# export HF_HOME=/work/commons/huggingface/hub\n",
    "\n",
    "# \"facebook/esm1v_t33_650M_UR90S_1\" not working\n",
    "\n",
    "from transformers import EsmForMaskedLM, EsmTokenizer\n",
    "\n",
    "model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "model = EsmForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "seq_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea2e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list(data[\"seq\"])\n",
    "fitness = torch.tensor(data[\"log_fitness\"].values, dtype=torch.float32)\n",
    "positions = [[int(p) for p in str(pos).split(',')] if isinstance(pos, str) else [pos] for pos in data['mutated_position']]\n",
    "pids = data[\"PID\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46953e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 1271, 1271, 1271)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences), len(fitness), len(positions), len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8203b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34d4152e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/BRCA1_HUMAN_Fields2015-e3/wt.fasta'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1be651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDLSALRVEEVQNVINAMQKILECPICLELIKEPVSTKCDHIFCKFCMLKLLNQKKGPSQCPLCKNDITKRSLQESTRFSQLVEELLKIICAFQLDTGLEYANSYNFAKK\n"
     ]
    }
   ],
   "source": [
    "for seq_record in SeqIO.parse(wt_path, \"fasta\"):\n",
    "    wt = str(seq_record.seq)\n",
    "    print(wt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21e021",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50ac39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutation_Set(Dataset):\n",
    "    def __init__(self, data, fname, tokenizer, sep_len=1024):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = sep_len\n",
    "        self.seq, self.attention_mask = tokenizer(list(self.data['seq']), padding='max_length',\n",
    "                                                  truncation=True,\n",
    "                                                  max_length=self.seq_len).values()\n",
    "        wt_path = os.path.join('data', fname, 'wt.fasta')\n",
    "        for seq_record in SeqIO.parse(wt_path, \"fasta\"):\n",
    "            wt = str(seq_record.seq)\n",
    "        target = [wt]*len(self.data)\n",
    "        self.target, self.tgt_mask = tokenizer(target, padding='max_length', truncation=True,\n",
    "                                               max_length=self.seq_len).values()\n",
    "        self.score = torch.tensor(np.array(self.data['log_fitness']))\n",
    "        self.pid = np.asarray(data['PID'])\n",
    "\n",
    "        if type(list(self.data['mutated_position'])[0]) != str:\n",
    "            self.position = [[u] for u in self.data['mutated_position']]\n",
    "\n",
    "        else:\n",
    "\n",
    "            temp = [u.split(',') for u in self.data['mutated_position']]\n",
    "            self.position = []\n",
    "            for u in temp:\n",
    "                pos = [int(v) for v in u]\n",
    "                self.position.append(pos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.seq[idx], self.attention_mask[idx], self.target[idx],self.tgt_mask[idx] ,self.position[idx], self.score[idx], self.pid[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.score)\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        seq = torch.tensor(np.array([u[0] for u in data]))\n",
    "        att_mask = torch.tensor(np.array([u[1] for u in data]))\n",
    "        tgt = torch.tensor(np.array([u[2] for u in data]))\n",
    "        tgt_mask = torch.tensor(np.array([u[3] for u in data]))\n",
    "        pos = [torch.tensor(u[4]) for u in data]\n",
    "        score = torch.tensor(np.array([u[5] for u in data]), dtype=torch.float32)\n",
    "        pid = torch.tensor(np.array([u[6] for u in data]))\n",
    "        return seq, att_mask, tgt, tgt_mask, pos, score, pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ddde2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Mutation_Set(data, dataset_name, tokenizer, sep_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c90f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1271)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.attention_mask[0]), len(dataset.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f65c15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(dataset_name, seed, shot, frac=0.2):\n",
    "    '''\n",
    "    sample the train data and test data\n",
    "    :param seed: sample seed\n",
    "    :param frac: the fraction of testing data, default to 0.2\n",
    "    :param shot: the size of training data\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(f'data/{dataset_name}/data.csv', index_col=0)\n",
    "    test_data = data.sample(frac=frac, random_state=seed)\n",
    "    train_data = data.drop(test_data.index)\n",
    "    \n",
    "    # low-N training\n",
    "    # prepares the few labeled mutants for fine-tuning while leaving the rest for testing or validation\n",
    "    kshot_data = train_data.sample(n=shot, random_state=seed)\n",
    "    \n",
    "    assert len(kshot_data) == shot, (\n",
    "        f'expected {shot} train examples, received {len(train_data)}')\n",
    "\n",
    "    kshot_data.to_csv(f'data/{dataset_name}/train.csv')\n",
    "    test_data.to_csv(f'data/{dataset_name}/test.csv')\n",
    "\n",
    "\n",
    "def split_train(dataset_name):\n",
    "    '''\n",
    "    five equal split training data, one of which will be used as validation set when training ConFit\n",
    "    '''\n",
    "    train = pd.read_csv(f'data/{dataset_name}/train.csv', index_col=0)\n",
    "    tlen = int(np.ceil(len(train) / 5))\n",
    "    start = 0\n",
    "    for i in range(1, 5):\n",
    "        csv = train[start:start + tlen]\n",
    "        start += tlen\n",
    "        csv.to_csv(f'data/{dataset_name}/train_{i}.csv')\n",
    "    csv = train[start:]\n",
    "    csv.to_csv(f'data/{dataset_name}/train_{5}.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def spearman(y_pred, y_true):\n",
    "    if np.var(y_pred) < 1e-6 or np.var(y_true) < 1e-6:\n",
    "        return 0.0\n",
    "    return spearmanr(y_pred, y_true)[0]\n",
    "\n",
    "def compute_stat(sr):\n",
    "    sr = np.asarray(sr)\n",
    "    mean = np.mean(sr)\n",
    "    std = np.std(sr)\n",
    "    sr = (sr,)\n",
    "    ci = list(bootstrap(sr, np.mean).confidence_interval)\n",
    "    return mean, std, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "557be2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BT_loss(scores, golden_score):\n",
    "    loss = torch.tensor(0.)\n",
    "    loss = loss.cuda()\n",
    "    for i in range(len(scores)):\n",
    "        for j in range(i, len(scores)):\n",
    "            if golden_score[i] > golden_score[j]:\n",
    "                loss += torch.log(1+torch.exp(scores[j]-scores[i]))\n",
    "            else:\n",
    "                loss += torch.log(1+torch.exp(scores[i]-scores[j]))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def KLloss(logits, logits_reg, seq, att_mask):\n",
    "\n",
    "    creterion_reg = torch.nn.KLDivLoss(reduction='mean')\n",
    "    batch_size = int(seq.shape[0])\n",
    "\n",
    "    loss = torch.tensor(0.)\n",
    "    loss = loss.cuda()\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    probs_reg = torch.softmax(logits_reg, dim=-1)\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        probs_i = probs[i]\n",
    "        probs_reg_i = probs_reg[i]\n",
    "\n",
    "\n",
    "        seq_len = torch.sum(att_mask[i])\n",
    "\n",
    "        reg = probs_reg_i[torch.arange(0, seq_len), seq[i, :seq_len]]\n",
    "        pred = probs_i[torch.arange(0, seq_len), seq[i, :seq_len]]\n",
    "\n",
    "        loss += creterion_reg(reg.log(), pred)\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, testloader, tokenizer, accelerator, istest=False):\n",
    "    model.eval()\n",
    "    seq_list = []\n",
    "    score_list = []\n",
    "    gscore_list = []\n",
    "    device = next(model.parameters()).device  # Get model's device (e.g., 'cuda:0')\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(testloader):\n",
    "            seq, mask = data[0].to(device), data[1].to(device)\n",
    "            wt, wt_mask = data[2].to(device), data[3].to(device)\n",
    "            pos = [p.to(device) for p in data[4]]\n",
    "            golden_score = data[5].to(device)\n",
    "            pid = data[6].to(device)\n",
    "            if istest:\n",
    "                if accelerator is not None:\n",
    "                    pid = accelerator.gather(pid)\n",
    "                for s in pid:\n",
    "                    seq_list.append(s.cpu())\n",
    "\n",
    "            score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "\n",
    "            if accelerator is not None:\n",
    "                score = accelerator.gather(score)\n",
    "                golden_score = accelerator.gather(golden_score)\n",
    "            score = np.asarray(score.cpu())\n",
    "            golden_score = np.asarray(golden_score.cpu())\n",
    "            score_list.extend(score)\n",
    "            gscore_list.extend(golden_score)\n",
    "    score_list = np.asarray(score_list)\n",
    "    gscore_list = np.asarray(gscore_list)\n",
    "    sr = spearman(score_list, gscore_list)\n",
    "\n",
    "    if istest:\n",
    "        seq_list = np.asarray(seq_list)\n",
    "\n",
    "        return sr, score_list, seq_list\n",
    "    else:\n",
    "        return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1919690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training size\n",
    "shot = 100\n",
    "seed = 0\n",
    "sample_data(dataset_name, seed, shot)\n",
    "split_train(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a880d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f'data/{dataset_name}/train.csv', index_col=0)\n",
    "val_data = pd.read_csv(f'data/{dataset_name}/train_1.csv', index_col=0)\n",
    "test_data = pd.read_csv(f'data/{dataset_name}/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94d8b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Mutation_Set(train_data, dataset_name, tokenizer, sep_len=seq_len)\n",
    "val_dataset = Mutation_Set(val_data, dataset_name, tokenizer, sep_len=seq_len)\n",
    "test_dataset = Mutation_Set(test_data, dataset_name, tokenizer, sep_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "390a073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          collate_fn=train_dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False,\n",
    "                        collate_fn=val_dataset.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False,\n",
    "                         collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a5cfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58a5b789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, torch.Size([8, 1024]), torch.Size([8, 1024]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch), batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ab68e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,027,520 || all params: 654,384,054 || trainable%: 0.3098364007506821\n"
     ]
    }
   ],
   "source": [
    "base_model = model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=None,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"key\", \"value\"])\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3504fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [01:42<00:00, 14.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,864,320 || all params: 15,142,217,634 || trainable%: 0.0519363820418327\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"facebook/esm2_t48_15B_UR50D\"\n",
    "# base_model = EsmForMaskedLM.from_pretrained(model_name, \n",
    "#                                             torch_dtype=torch.float16,\n",
    "#                                             # low_cpy_mem_usage=True,\n",
    "#                                             use_auth_token=True)\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     r=8,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     target_modules=[\"query\", \"value\"])\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d62332a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): EsmForMaskedLM(\n",
       "      (esm): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-32): 33 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (lm_head): EsmLMHead(\n",
       "        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=1280, out_features=33, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "accelerator = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "lambda_reg = 0.1\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7844d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/shannon/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/functional.py:3355: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2.368814775943756\n",
      "Epoch 1, Validation Spearman: 0.675187969924812\n",
      "Epoch 2, Training Loss: 2.4839784908294678\n",
      "Epoch 2, Validation Spearman: 0.7473684210526315\n",
      "Epoch 3, Training Loss: 2.216451325416565\n",
      "Epoch 3, Validation Spearman: 0.7684210526315788\n",
      "Epoch 4, Training Loss: 1.897665684223175\n",
      "Epoch 4, Validation Spearman: 0.7428571428571428\n",
      "Epoch 5, Training Loss: 2.2363506412506102\n",
      "Epoch 5, Validation Spearman: 0.7639097744360903\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        seq, mask, wt, wt_mask, pos, golden_score, pid = batch\n",
    "        seq, mask, wt, wt_mask, golden_score, pid = seq.to(device), mask.to(device), wt.to(device), wt_mask.to(device), golden_score.to(device), pid.to(device)\n",
    "        pos = [p.to(device) for p in pos]\n",
    "        score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "        l_bt = BT_loss(score, golden_score)\n",
    "        l_reg = KLloss(logits, logits, seq, mask)\n",
    "        loss = l_bt + lambda_reg * l_reg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {total_loss / len(train_loader)}')\n",
    "    \n",
    "    val_sr = evaluate(model, val_loader, tokenizer, None)\n",
    "    print(f'Epoch {epoch + 1}, Validation Spearman: {val_sr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11af946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b6819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71555633",
   "metadata": {},
   "source": [
    "## Integrate with SPURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c96fe4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
